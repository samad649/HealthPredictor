{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RR_6NMg-fMAv"
   },
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKh0RDHssrLB",
    "outputId": "8cd73761-190d-4417-fa21-5d9cfce15661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admissions_df loaded successfully.\n",
      "diagnosis_codes_df loaded successfully.\n",
      "diagnosis_df loaded successfully.\n",
      "notes_df loaded successfully.\n",
      "patients_df loaded successfully.\n",
      "prescription_df loaded successfully.\n",
      "\n",
      "DataFrame: admissions_df\n",
      "   row_id  subject_id  hadm_id            admittime            dischtime  \\\n",
      "0       1           2   163353  2138-07-17 19:04:00  2138-07-21 15:48:00   \n",
      "1       2           3   145834  2101-10-20 19:08:00  2101-10-31 13:58:00   \n",
      "2       4           5   178980  2103-02-02 04:31:00  2103-02-04 12:15:00   \n",
      "3       6           7   118037  2121-05-23 15:05:00  2121-05-27 11:57:00   \n",
      "4       7           8   159514  2117-11-20 10:22:00  2117-11-24 14:20:00   \n",
      "\n",
      "  deathtime admission_type         admission_location discharge_location  \\\n",
      "0       NaN        NEWBORN  PHYS REFERRAL/NORMAL DELI               HOME   \n",
      "1       NaN      EMERGENCY       EMERGENCY ROOM ADMIT                SNF   \n",
      "2       NaN        NEWBORN  PHYS REFERRAL/NORMAL DELI               HOME   \n",
      "3       NaN        NEWBORN  PHYS REFERRAL/NORMAL DELI               HOME   \n",
      "4       NaN        NEWBORN  PHYS REFERRAL/NORMAL DELI               HOME   \n",
      "\n",
      "  insurance language       religion marital_status ethnicity  \\\n",
      "0   Private      NaN  NOT SPECIFIED            NaN     ASIAN   \n",
      "1  Medicare      NaN       CATHOLIC        MARRIED     WHITE   \n",
      "2   Private      NaN       BUDDHIST            NaN     ASIAN   \n",
      "3   Private      NaN       CATHOLIC            NaN     WHITE   \n",
      "4   Private      NaN       CATHOLIC            NaN     WHITE   \n",
      "\n",
      "             edregtime            edouttime    diagnosis  \\\n",
      "0                  NaN                  NaN      NEWBORN   \n",
      "1  2101-10-20 17:09:00  2101-10-20 19:24:00  HYPOTENSION   \n",
      "2                  NaN                  NaN      NEWBORN   \n",
      "3                  NaN                  NaN      NEWBORN   \n",
      "4                  NaN                  NaN      NEWBORN   \n",
      "\n",
      "   hospital_expire_flag  has_chartevents_data  \n",
      "0                     0                     1  \n",
      "1                     0                     1  \n",
      "2                     0                     1  \n",
      "3                     0                     1  \n",
      "4                     0                     1  \n",
      "\n",
      "DataFrame: diagnosis_codes_df\n",
      "   row_id  icd9_code               short_title  \\\n",
      "0       1       1716   Erythem nod tb-oth test   \n",
      "1       2       1720    TB periph lymph-unspec   \n",
      "2       3       1721   TB periph lymph-no exam   \n",
      "3       4       1722  TB periph lymph-exam unk   \n",
      "4       5       1723  TB periph lymph-micro dx   \n",
      "\n",
      "                                          long_title  \n",
      "0  Erythema nodosum with hypersensitivity reactio...  \n",
      "1  Tuberculosis of peripheral lymph nodes, unspec...  \n",
      "2  Tuberculosis of peripheral lymph nodes, bacter...  \n",
      "3  Tuberculosis of peripheral lymph nodes, bacter...  \n",
      "4  Tuberculosis of peripheral lymph nodes, tuberc...  \n",
      "\n",
      "DataFrame: diagnosis_df\n",
      "   row_id  subject_id  hadm_id  seq_num icd9_code\n",
      "0       1           2   163353        1     V3001\n",
      "1       2           2   163353        2      V053\n",
      "2       3           2   163353        3      V290\n",
      "3       4           3   145834        1      0389\n",
      "4       5           3   145834        2     78559\n",
      "\n",
      "DataFrame: notes_df\n",
      "   row_id  subject_id  hadm_id            chartdate            charttime  \\\n",
      "0  738407       20409      NaN  2119-01-04 00:00:00  2119-01-04 12:59:00   \n",
      "1  738408       20409      NaN  2119-01-09 00:00:00  2119-01-09 13:05:00   \n",
      "2  738409       20409      NaN  2119-01-16 00:00:00  2119-01-16 21:24:00   \n",
      "3  738410       20409      NaN  2119-01-18 00:00:00  2119-01-18 13:24:00   \n",
      "4  738411       20409      NaN  2119-01-18 00:00:00  2119-01-18 15:45:00   \n",
      "\n",
      "   storetime   category                        description  cgid  iserror  \\\n",
      "0        NaN  Radiology      ABDOMEN U.S. (COMPLETE STUDY)   NaN      NaN   \n",
      "1        NaN  Radiology             MR LIVER WITH CONTRAST   NaN      NaN   \n",
      "2        NaN  Radiology                CHEST (PORTABLE AP)   NaN      NaN   \n",
      "3        NaN  Radiology                     CT ABD W&W/O C   NaN      NaN   \n",
      "4        NaN  Radiology  PARACENTESIS DIAG. OR THERAPEUTIC   NaN      NaN   \n",
      "\n",
      "                                                text  \n",
      "0  [**2119-1-4**] 12:59 PM\\n ABDOMEN U.S. (COMPLE...  \n",
      "1  [**2119-1-9**] 1:05 PM\\n MR LIVER WITH CONTRAS...  \n",
      "2  [**2119-1-16**] 9:24 PM\\n CHEST (PORTABLE AP) ...  \n",
      "3  [**2119-1-18**] 1:24 PM\\n CT ABD W&W/O C; CT P...  \n",
      "4  [**2119-1-18**] 3:45 PM\\n PARACENTESIS DIAG. O...  \n",
      "\n",
      "DataFrame: patients_df\n",
      "   row_id  subject_id gender                  dob                  dod  \\\n",
      "0       1           2      M  2138-07-17 00:00:00                  NaN   \n",
      "1       2           3      M  2025-04-11 00:00:00  2102-06-14 00:00:00   \n",
      "2       4           5      M  2103-02-02 00:00:00                  NaN   \n",
      "3       6           7      F  2121-05-23 00:00:00                  NaN   \n",
      "4       7           8      M  2117-11-20 00:00:00                  NaN   \n",
      "\n",
      "  dod_hosp              dod_ssn  expire_flag  \n",
      "0      NaN                  NaN            0  \n",
      "1      NaN  2102-06-14 00:00:00            1  \n",
      "2      NaN                  NaN            0  \n",
      "3      NaN                  NaN            0  \n",
      "4      NaN                  NaN            0  \n",
      "\n",
      "DataFrame: prescription_df\n",
      "   row_id  subject_id  hadm_id  icustay_id            startdate  \\\n",
      "0    1089       22773   197440         NaN  2127-10-15 00:00:00   \n",
      "1    1090       22773   197440         NaN  2127-10-15 00:00:00   \n",
      "2    1091       22773   197440         NaN  2127-10-15 00:00:00   \n",
      "3    1092       22773   197440         NaN  2127-10-15 00:00:00   \n",
      "4    1093       22773   197440         NaN  2127-10-15 00:00:00   \n",
      "\n",
      "               enddate drug_type                    drug  \\\n",
      "0  2127-10-16 00:00:00      MAIN           Acetaminophen   \n",
      "1  2127-10-16 00:00:00      MAIN        Calcium Chloride   \n",
      "2  2127-10-16 00:00:00      MAIN               Lorazepam   \n",
      "3  2127-10-16 00:00:00      MAIN                 Desitin   \n",
      "4  2127-10-16 00:00:00      MAIN  Nystatin-Triamcinolone   \n",
      "\n",
      "            drug_name_poe  drug_name_generic formulary_drug_cd      gsn  \\\n",
      "0           Acetaminophen      Acetaminophen           ACET325   4489.0   \n",
      "1        Calcium Chloride   Calcium Chloride          CALC100I   1348.0   \n",
      "2               Lorazepam          Lorazepam            LORA2I   3753.0   \n",
      "3                 Desitin            Desitin           DESI30O  48743.0   \n",
      "4  Nystatin-Triamcinolone  Nystatin/Triamcin             MYCOC  48529.0   \n",
      "\n",
      "           ndc  prod_strength dose_val_rx dose_unit_rx form_val_disp  \\\n",
      "0     45050130      325MG TAB     325-650           mg           1-2   \n",
      "1    186116502  1GM/10ML VIAL           1           gm             1   \n",
      "2     24115510     2MG/ML SYR       0.5-2           mg        0.25-1   \n",
      "3  74300000068      30gm Tube           1         Appl          0.01   \n",
      "4    168008130     CREAM;30GM           1         Appl             1   \n",
      "\n",
      "  form_unit_disp route  \n",
      "0            TAB    PO  \n",
      "1           VIAL    IV  \n",
      "2             ml    IV  \n",
      "3           TUBE    TP  \n",
      "4           APPL    TP  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self):\n",
    "        ACCESS_KEY = 'ENTER_ACCESS_KEY'\n",
    "        SECRET_KEY = 'ENTER_SECRET_KEY'\n",
    "        session = boto3.Session(\n",
    "        aws_access_key_id=ACCESS_KEY,\n",
    "        aws_secret_access_key=SECRET_KEY)\n",
    "        # Initializing file paths for the MIMIC-III data\n",
    "        self.s3 = boto3.client('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY)\n",
    "        self.bucket_name = 'mimic-iv-dataset'\n",
    "        self.data_files = {\n",
    "            \"admissions_df\": \"ADMISSIONS.csv.gz\",\n",
    "            \"diagnosis_codes_df\": \"D_ICD_DIAGNOSES.csv.gz\",\n",
    "            \"diagnosis_df\": \"DIAGNOSES_ICD.csv.gz\",\n",
    "            \"notes_df\": \"NOTEEVENTS.csv.gz\",\n",
    "            \"patients_df\": \"PATIENTS.csv.gz\",\n",
    "            \"prescription_df\": \"PRESCRIPTIONS.csv.gz\"\n",
    "        }\n",
    "        # Dictionary to hold DataFrames\n",
    "        self.dataframes = {}\n",
    "\n",
    "    def load_data(self, nrows=1000):\n",
    "        # Load each CSV file from S3 into a DataFrame\n",
    "        for df_name, file_key in self.data_files.items():\n",
    "            try:\n",
    "\n",
    "                obj = self.s3.get_object(Bucket=self.bucket_name, Key=file_key)\n",
    "                self.dataframes[df_name] = pd.read_csv(\n",
    "                    io.BytesIO(obj['Body'].read()),\n",
    "                    compression='gzip',\n",
    "                    nrows=nrows\n",
    "                )\n",
    "                print(f\"{df_name} loaded successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_key}: {e}\")\n",
    "\n",
    "    def get_dataframe(self, df_name):\n",
    "        # Return a specific DataFrame by name\n",
    "        return self.dataframes.get(df_name, None)\n",
    "\n",
    "    def print_head(self):\n",
    "        # Print the first 5 rows of each DataFrame\n",
    "        for df_name, df in self.dataframes.items():\n",
    "            if df is not None:\n",
    "                print(f\"\\nDataFrame: {df_name}\")\n",
    "                print(df.head())\n",
    "            else:\n",
    "                print(f\"\\nDataFrame: {df_name} could not be loaded.\")\n",
    "\n",
    "data_set = DataSet()\n",
    "data_set.load_data(nrows=100)\n",
    "data_set.print_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-sNB9GKtAKi",
    "outputId": "31359fec-adce-427a-c078-e42f5f3a5cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admissions_df loaded successfully.\n",
      "diagnosis_codes_df loaded successfully.\n",
      "diagnosis_df loaded successfully.\n",
      "notes_df loaded successfully.\n",
      "patients_df loaded successfully.\n",
      "prescription_df loaded successfully.\n",
      "   id notes                                    diagnosis_codes\n",
      "0   2   NaN                                [V3001, V053, V290]\n",
      "1   3   NaN  [0389, 78559, 5849, 4275, 41071, 4280, 6826, 4...\n",
      "2   5   NaN                                [V3000, V053, V290]\n",
      "3   7   NaN                                [V3001, V053, V290]\n",
      "4   8   NaN              [V3001, 7706, 7746, V290, V502, V053]\n",
      "(13, 2011)\n",
      "(5, 2011)\n",
      "(13, 93)\n",
      "(5, 93)\n",
      "Accuracy: 0.6\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         0\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       1.00      0.00      0.00         2\n",
      "           9       1.00      1.00      1.00         0\n",
      "          10       1.00      1.00      1.00         0\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       1.00      1.00      1.00         0\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      0.00      0.00         1\n",
      "          17       1.00      1.00      1.00         0\n",
      "          18       1.00      1.00      1.00         0\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       1.00      1.00      1.00         0\n",
      "          21       1.00      1.00      1.00         0\n",
      "          22       1.00      1.00      1.00         0\n",
      "          23       1.00      1.00      1.00         0\n",
      "          24       1.00      0.00      0.00         1\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      1.00      1.00         0\n",
      "          27       1.00      1.00      1.00         0\n",
      "          28       1.00      1.00      1.00         2\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          31       1.00      1.00      1.00         0\n",
      "          32       0.80      1.00      0.89         4\n",
      "          33       1.00      1.00      1.00         0\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      0.00      0.00         2\n",
      "          36       1.00      0.50      0.67         4\n",
      "          37       1.00      1.00      1.00         0\n",
      "          38       1.00      1.00      1.00         2\n",
      "          39       1.00      0.00      0.00         1\n",
      "          40       1.00      1.00      1.00         0\n",
      "          41       1.00      1.00      1.00         2\n",
      "          42       1.00      0.00      0.00         1\n",
      "          43       1.00      1.00      1.00         0\n",
      "          44       0.67      1.00      0.80         2\n",
      "          45       1.00      0.00      0.00         1\n",
      "          46       1.00      1.00      1.00         1\n",
      "          47       1.00      1.00      1.00         0\n",
      "          48       1.00      1.00      1.00         2\n",
      "          49       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       1.00      0.00      0.00         1\n",
      "          52       1.00      1.00      1.00         2\n",
      "          53       1.00      1.00      1.00         0\n",
      "          54       1.00      1.00      1.00         0\n",
      "          55       0.67      1.00      0.80         2\n",
      "          56       1.00      1.00      1.00         0\n",
      "          57       1.00      1.00      1.00         2\n",
      "          58       1.00      1.00      1.00         0\n",
      "          59       1.00      1.00      1.00         0\n",
      "          60       1.00      1.00      1.00         2\n",
      "          61       1.00      1.00      1.00         2\n",
      "          62       1.00      0.67      0.80         3\n",
      "          63       1.00      1.00      1.00         0\n",
      "          64       1.00      1.00      1.00         0\n",
      "          65       1.00      1.00      1.00         0\n",
      "          66       1.00      1.00      1.00         0\n",
      "          67       1.00      1.00      1.00         0\n",
      "          68       1.00      1.00      1.00         0\n",
      "          69       1.00      1.00      1.00         0\n",
      "          70       1.00      1.00      1.00         0\n",
      "          71       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         2\n",
      "          73       1.00      1.00      1.00         0\n",
      "          74       1.00      1.00      1.00         0\n",
      "          75       1.00      1.00      1.00         0\n",
      "          76       1.00      1.00      1.00         0\n",
      "          77       1.00      1.00      1.00         0\n",
      "          78       1.00      1.00      1.00         0\n",
      "          79       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         0\n",
      "          81       1.00      1.00      1.00         2\n",
      "          82       1.00      0.00      0.00         1\n",
      "          83       1.00      1.00      1.00         2\n",
      "          84       1.00      1.00      1.00         0\n",
      "          85       1.00      1.00      1.00         2\n",
      "          86       1.00      1.00      1.00         1\n",
      "          87       1.00      1.00      1.00         0\n",
      "          88       1.00      1.00      1.00         0\n",
      "          89       1.00      1.00      1.00         2\n",
      "          90       1.00      1.00      1.00         0\n",
      "          91       1.00      1.00      1.00         2\n",
      "          92       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       0.95      0.85      0.90        93\n",
      "   macro avg       0.99      0.89      0.89        93\n",
      "weighted avg       0.97      0.85      0.84        93\n",
      " samples avg       0.65      0.62      0.63        93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/multiclass.py:87: UserWarning: Label not 39 is present in all training examples.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/multiclass.py:87: UserWarning: Label not 42 is present in all training examples.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/multiclass.py:87: UserWarning: Label not 45 is present in all training examples.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/multiclass.py:87: UserWarning: Label not 51 is present in all training examples.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/multiclass.py:87: UserWarning: Label not 82 is present in all training examples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "class NaiveBayes:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    def __init__(self):\n",
    "        self.counter = CountVectorizer()\n",
    "\n",
    "        # Use OneVsRestClassifier to handle multi-label classification\n",
    "        self.model = OneVsRestClassifier(MultinomialNB())\n",
    "\n",
    "        self.data = DataSet()\n",
    "\n",
    "        self.data.load_data(nrows=5000)\n",
    "\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "\n",
    "    # Extract all the needed data and store in df\n",
    "    def process_data(self):\n",
    "        admissions = self.data.dataframes[\"admissions_df\"]\n",
    "        self.df['id'] = admissions['subject_id']\n",
    "\n",
    "        notes = self.data.dataframes[\"notes_df\"]\n",
    "        # Get every text from notes_df associated with the subject id\n",
    "        id_notes = {}\n",
    "        for _, row in notes.iterrows():\n",
    "            subject_id = row['subject_id']\n",
    "            text = row['text']\n",
    "\n",
    "            if subject_id not in id_notes:\n",
    "                id_notes[subject_id] = text\n",
    "            else:\n",
    "                id_notes[subject_id] += ' ' + text\n",
    "        # Store each set of notes to its id\n",
    "        self.df['notes'] = self.df['id'].map(id_notes)\n",
    "\n",
    "        # Store all the diagnosis with each subject id\n",
    "        diagnosis = self.data.dataframes[\"diagnosis_df\"]\n",
    "        id_diagnosis = {}\n",
    "\n",
    "        for _, row in diagnosis.iterrows():\n",
    "            subject_id = row['subject_id']\n",
    "            diag_code = row['icd9_code']\n",
    "\n",
    "            if subject_id not in id_diagnosis:\n",
    "                id_diagnosis[subject_id] = [diag_code]\n",
    "            else:\n",
    "                id_diagnosis[subject_id].append(diag_code)\n",
    "\n",
    "        self.df['diagnosis_codes'] = self.df['id'].map(id_diagnosis)\n",
    "\n",
    "        print(self.df.head())\n",
    "\n",
    "    def train(self):\n",
    "        # Drop rows where 'notes' or 'diagnosis_codes' are NaN\n",
    "        self.df.dropna(subset=['notes', 'diagnosis_codes'], inplace=True)\n",
    "\n",
    "        # Replace non-list entries with an empty list\n",
    "        self.df['diagnosis_codes'] = self.df['diagnosis_codes'].apply(\n",
    "            lambda x: x if isinstance(x, list) else []\n",
    "        )\n",
    "\n",
    "        # Check if there are still any NaN values\n",
    "        if self.df['diagnosis_codes'].isna().sum() > 0:\n",
    "            print(\"Warning: There are still NaN values in 'diagnosis_codes' after processing.\")\n",
    "\n",
    "        X = self.df['notes']\n",
    "        y = self.mlb.fit_transform(self.df['diagnosis_codes'])\n",
    "\n",
    "        # Train-test split ensuring all classes are represented\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "        X_train_vectorized = self.counter.fit_transform(X_train)\n",
    "        X_test_vectorized = self.counter.transform(X_test)\n",
    "\n",
    "        print(X_train_vectorized.shape)\n",
    "        print(X_test_vectorized.shape)\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "\n",
    "        self.model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "        y_pred = self.model.predict(X_test_vectorized)\n",
    "\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_vectorized = self.counter.transform(X)\n",
    "\n",
    "        predictions = self.model.predict(X_vectorized)\n",
    "\n",
    "        diagnosis_codes = self.mlb.inverse_transform(predictions)\n",
    "\n",
    "        return diagnosis_codes\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nb_model = NaiveBayes()\n",
    "    nb_model.process_data()\n",
    "    nb_model.train()\n",
    "        # Test nurse notes\n",
    "    nurse_notes = [\n",
    "        \"Patient is a 55-year-old male presenting with a history of hypertension and diabetes. Complains of sharp, intermittent chest pain radiating to the left arm. Denies nausea or shortness of breath. EKG shows normal sinus rhythm.\",\n",
    "        \"A 68-year-old female with a history of asthma presents with a 3-day history of fever and dry cough. No shortness of breath, but reports fatigue. Chest X-ray suggests mild consolidation.\",\n",
    "        \"Post-op patient after knee replacement surgery. Reports mild pain in the surgical site, 4/10 on the pain scale. No signs of infection, incision is clean and dry. Patient is ambulating with assistance.\",\n",
    "        \"Patient is a 40-year-old male presenting with acute lower abdominal pain and bloating. Reports nausea but no vomiting. Last bowel movement was 2 days ago. CT scan is pending for suspected appendicitis.\",\n",
    "        \"Patient is a 60-year-old female with Type 2 diabetes, presenting with a blood glucose level of 220 mg/dL. Complaints of increased thirst and urination. Current medications: metformin and insulin.\",\n",
    "        \"Patient is a 33-year-old male presenting with a 1-week history of lower back pain after lifting heavy objects. Pain is dull and constant, worsened with movement. Denies leg weakness or numbness.\",\n",
    "        \"Patient is a 45-year-old female with a history of hypertension. Complains of daily headaches and blurred vision, especially in the morning. No known history of migraines. BP is elevated at 160/100.\"\n",
    "    ]\n",
    "\n",
    "    # Make predictions for each nurse note\n",
    "    predictions = nb_model.predict(nurse_notes)\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        print(f\"Prediction for Nurse Note {i+1}: {prediction}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
